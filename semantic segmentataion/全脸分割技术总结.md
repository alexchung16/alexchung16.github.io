# 全脸分割技术总结

## 概述

全脸分割指的对给定人脸进行像素级的分类，将人脸头像分为前景和背景区域。其中前景区域包含眼睛、人脸皮肤区域和上下嘴唇区域；口腔内部如舌头等属于背景区域，手指等其他遮挡物也判定为遮挡区域。

全脸分割任务的评价指标主要包含两个方面精度和速度，其中精度指的是分割的结果准确，对于视频来说稳定性也是一个衡量指标；速度指的是模型在 IOS 和 Android 双端不同中高端机型的推理速度。在纯净环境下，实时模型在高端机上的推理速度要达到 5ms 左右。 

## 算法实现

### 数据处理

* 训练时输入网络的人脸图像是根据人脸点对齐到标准人脸并利用**umeyma**方法截取的固定大小的图像，对应的推理时输入模型的图像也要做对应的变换。
* 关于数据增强方面包括在线数据增强和离线数据增强。其中在线数据增强除了包括常用的颜色抖动和形状变换，还包括各种素材比如口罩、笔、眼镜等的遮挡。数据增强需要根据实际表现做相应调整，比如也可以单独对嘴唇利用各种唇膏颜色数据增强。数据增强也可以做离线的数据增强，优点是能够直观看到遮挡的效果，缺点是损失一定的随机性。
* 如果要做边缘监督需要根据 mask 生成对应的边缘；这里可能涉及到边缘提取算子的选择，通常包括 canny边缘检测器、laplacian 边缘检测和 distance_transform 等。
* 对于分割来说，涉及到mask 的缩放一般只能用最近邻差值，其他差值方法都会引入其他像素值。

### 模型框架

* 模型框架方面一般都是 U-Net, 当前最新的一些实时分割算法框架比如BiSeNet、DDRNet 等由于分辨率压缩的原因都不能满足人脸分割这种对应分割的细节精度要求很高的场景。
* 为了提高边缘分割精度一般考虑引入边缘分支对模型进行监督，此外推理时是否利用边缘分支的特征也是网络设计的一个关键点。**实验效果而言，在保持相同计算量的情况下，将边缘分支的特征 concat 到主分支能够得到更优的分割精度。**
* 在上采样的过程中，多次的Upsample 操作可以有效消除生成的mask中边缘锯齿的问题。
* 为了降低模型的计算量从而提高推理速度，在模型设计时考虑使用大的卷积核和步数将图像分辨率快速降低。
* 注意力模块的选择也是模型设计的关键。
* 通过 NAS 搜索最优的网络结构实验证明也是一个可行的方式，能够取的不错的效果

### 目标函数

* 目标函数一般使用多个目标函数进行监督，这时目标函数对应的权重设置会对结果造成较大影响，需要通过多次实验结合人工经验设置。关于目标函数权重的选择可以考虑 NNI 库中的 [HPO(Hyperparameter Optimization)](https://nni.readthedocs.io/en/stable/hpo/overview.html) 框架搜索得到（后续尝试）。
* 交叉熵损失（Cross Entropy, CE）可以使用在大多数语义分割任务中， $L_{CE}=-\sum_{c=1}^{M}y_{c}log(p_{c})$ ，交叉损失墒的缺点是当正负样本的数量严重不平衡时，多数样本的损失会占据主导，从而少样本的的损失被忽略。交叉熵损失有对应的变种损失，比如加权的交叉熵，基于困难负例挖掘的 OHEM 和 TopK 等损失。
* DICE/F1 损失在医学图像分割中被引入，用于缓解医学图像中严重的正负样例不平衡问题。$D = \frac{2TP}{2TP + FP + FN}$；IOU/Jaccard 损失 $J = \frac{TP}{TP + FP + FN}$​。进一步$J=\frac{D}{2-D}$，$D=\frac{2J}{1+J}$。
* 一致性损失，分别对原始的图像的image 和 mask 做两种随机大小的尺寸变换并记录两种变换的变换矩阵关系， 计算目标函数时利用变换矩阵转换其中一个变换的mask 到另一个变换的mask, 并计算两个mask之间的一致性损失。实验表明，pair-loss 有助于提高模型的分割精度。
* 边缘损失，为了优化分割的边缘精度，模型框架会引入边缘分支进行监督，对应的损失函数即边缘损失。边缘损失一般使用交叉墒损失。由于正（边缘）负（背景）样例的严重不平衡，考虑使用加权的交叉熵损失作为目标函数，$L_{hed} = -\beta \sum_{j\in Y_{+}}g_{i}logs_{i} - (1-\beta)\sum_{j\in Y_{-}}g_{i}logs_{i}$, 其中$\beta = \frac{|Y_{-}|}{|Y_{+}|+|Y_{-}|}$。
* RMI 损失， 

### 训练策略

* 优化器考虑使用 AdamW, 是针对 Adam 的泛化性提出的一种改进的优化器， 优化器中内在地包含正则化优化项
* 学习率策略考虑使用CosineAnnealingWarmRestarts，是一种余弦退火学习策略，通过多次的退火达到最优结果。
* 优化在实际机型上跑时会采用FP16 的量化精度，因此在训练过程中考虑采用混合精度训练，提高模型量化推理时的精度。

## Trick

* 当实际测试中某些情况下的分割情况比较差的时候，可以考虑做针对性的数据增强。比如模型对手指遮挡的分割效果比较差，可以通过离线的数据增益，对无遮挡图像添加手指遮挡素材，形成新的训练数据集加入训练。

* 当引入混合精度训练或者训练小模型时前期可能会出现梯度爆炸的问题，表现为损失为Nan。实验表明，可以通过在训练前期引入学习率预热(WarmUp)的措施解决这个问题。具体的预热曲线和预热周期需要根据具体应用进行调整。

* 通过增加某一部位的权重的方式优化某一部位精度不work。

  



